# üöÄ CUDA Kernel Practice Repository

This repository is a collection of **CUDA `.cu` kernel implementations** that I have written while learning and practicing **GPU programming with NVIDIA CUDA**.  
The goal of this project is to strengthen my understanding of **parallel programming concepts**, experiment with **optimization techniques**, and build a personal reference library of CUDA kernels.

---

## üìå What‚Äôs Inside

Each file in this repository contains a standalone kernel (or set of kernels) written to solve a specific computational problem or demonstrate a GPU optimization pattern.  
Some examples include:
- üîπ **Vector and Matrix Operations** ‚Äì basic CUDA kernels for addition, multiplication, transposition.  
- üîπ **Shared Memory Optimization** ‚Äì using shared memory to reduce global memory access.  
- üîπ **Tiling and Blocking** ‚Äì techniques for optimizing matrix multiplication and stencil computations.  
- üîπ **Warp-Level Programming** ‚Äì experimenting with shuffle and reduction intrinsics. 
- üîπ **Memory Coalescing** ‚Äì reorganizing data accesses to maximize bandwidth.  
- üîπ **Parallel Reductions & Prefix Sums** ‚Äì classic GPU-friendly algorithms.  

> The repository is continuously growing as I learn and add new kernels.

---

## üéØ Purpose

- Practice writing efficient CUDA code.  
- Explore **GPU optimization techniques** (memory hierarchy, warps, occupancy, etc.).  
- Build a portfolio of work that demonstrates my progress in **high-performance GPU programming**.  
- Provide a reference for myself (and others learning CUDA).  

---

## ‚öôÔ∏è How to Run

1. Make sure you have:
   - NVIDIA GPU with CUDA support  
   - [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) installed  
   - A C++ compiler (e.g., `g++`)  

2. Compile any kernel file with `nvcc`:
   ```bash
   nvcc my_kernel.cu -o my_kernel
